# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html

# Raw data
iris_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/iris.csv

# Processed data
iris_data_processed:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/iris_processed.csv

# Processed data
iris_data_targeted:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/iris_targeted.csv

# Processed data
train:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/train.csv

# Processed data
valid:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/valid.csv

# Processed data
test:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/test.csv

# Preprocessing pipeline
sk_pipeline:
  type: pickle.PickleDataSet
  filepath: data/04_feature/sk_pipeline.pkl

# model
model:
  type: pickle.PickleDataSet
  filepath: data/06_models/model.pkl

# validation metrics
val_metrics:
  type: pickle.PickleDataSet
  filepath: data/06_model_output/val_metrics.pkl

# test_metrics and conditionals
results:
  type: pickle.PickleDataSet
  filepath: data/08_reporting/results.pkl